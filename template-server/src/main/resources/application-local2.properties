#apollo.meta=http://localhost:8081
server.port=7081
logging.level.root=INFO
swagger.enable=on
# mysql readwrite数据源
readwritedb.enable=on
jdbc.readwrite.driverClassName=com.mysql.jdbc.Driver
jdbc.readwrite.jdbcUrl=jdbc:mysql://localhost:3306/test?useUnicode=true&characterEncoding=utf8
jdbc.readwrite.username=hjm_dev
jdbc.readwrite.password=hjm_dev
jdbc.readwrite.connectionTimeout=5000
jdbc.readwrite.idleTimeout=1000
jdbc.readwrite.maximumPoolSize=50
jdbc.readwrite.minimumIdle=5
# read 数据源
readdb.enable=off
jdbc.read.driverClassName=com.mysql.jdbc.Driver
jdbc.read.jdbcUrl=jdbc:mysql://localhost:3306/test?useUnicode=true&characterEncoding=utf8
jdbc.read.username=hjm_dev
jdbc.read.password=hjm_dev
jdbc.read.connectionTimeout=5000
jdbc.read.idleTimeout=1000
jdbc.read.maximumPoolSize=50
jdbc.read.minimumIdle=5

# public redis
public.redis.host=localhost
public.redis.port=6379
public.redis.password=
# 连接超时时间（毫秒）
public.redis.timeout=10000
# dev环境用的是2 真是吊的不行,共享内存还要分,namespace都没.吐槽下
public.redis.database=2
# 连接池最大连接数（使用负值表示没有限制） 默认 8
public.redis.max-active=12
# 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1
public.redis.max-wait=-1
# 连接池中的最大空闲连接 默认 8
public.redis.max-idle=5
# 连接池中的最小空闲连接 默认 0
public.redis.min-idle=0
# primary redis
private.redis.host=localhost
private.redis.port=6379
private.redis.password=
# 连接超时时间（毫秒）
private.redis.timeout=10000
# dev环境用的是2 真是吊的不行,共享内存还要分,namespace都没.吐槽下
private.redis.database=1
# 连接池最大连接数（使用负值表示没有限制） 默认 8
private.redis.max-active=12
# 连接池最大阻塞等待时间（使用负值表示没有限制） 默认 -1
private.redis.max-wait=-1
# 连接池中的最大空闲连接 默认 8
private.redis.max-idle=5
# 连接池中的最小空闲连接 默认 0
private.redis.min-idle=0


#es
es.enable=off
elasticsearch.clusterNodes=localhost:9300
elasticsearch.clusterName=my-application
elasticsearch.properties.transport.tcp.connect_timeout=120s
elasticsearch.properties.client.transport.sniff=true
elasticsearch.properties.client.transport.ping_timeout=5s
elasticsearch.properties.client.transport.nodes_sampler_interval=5s
elasticsearch.properties.client.transport.ignore_cluster_name=false
#连接超时的时间
elasticsearch.readTimeout=5s
# kafka
kafka.enable=on
kafka.producer.bootstrap-servers=localhost:9092
kafka.producer.retries=3
kafka.producer.batch-size=8096
kafka.producer.linger-ms=5
kafka.producer.buffer-memory=33554432
kafka.poll.timeout=2000
kafka.consumer.bootstrap-servers=${kafka.producer.bootstrap-servers}
kafka.consumer.group-id=${spring.application.name}
kafka.consumer.enable-auto-commit=false
kafka.consumer.auto-commit-interval-ms=2000
kafka.consumer.session-timeout-ms=30000
kafka.consumer.max-poll-records=100
kafka.consumer.max.poll.interval.ms=5000
kafka.consumer.max.partition.fetch.bytes=4194304
#earliest,latest
kafka.consumer.auto-offset-reset=latest
heartbeat.interval.ms=2000
kafka.consumer.auto.startup=true
kafka.client.id=${random.uuid}